{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "from lifelines.utils import k_fold_cross_validation\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la ruta absoluta del directorio actual (donde está el script o notebook)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Subimos un nivel\n",
    "\n",
    "# Construir la ruta relativa a la carpeta \"Datos\"\n",
    "ruta_bdd = os.path.join(base_dir, \"Datos\", \"database.xlsx\")\n",
    "\n",
    "# Leer el archivo de datos\n",
    "data = pd.read_excel(ruta_bdd, sheet_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos los dataframes de cada key:\n",
    "data = pd.concat(data.values(), ignore_index=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Seleccionar las columnas relevantes para el modelo\n",
    "columns_to_use = [\"dias_230\", \"Caudal\", \"TPH\", \"% Solido\", \"Presion\", \"uso_230\", \"TPH_acum\", \"solido_dias\",\"solido_uso\",\"carga_solidos_efectiva\"]\n",
    "df_model = data[columns_to_use + [\"E\"]].dropna()  # Eliminar filas con valores faltantes\n",
    "\n",
    "# Ajustar el modelo de riesgos proporcionales de Cox\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_model, duration_col=\"dias_230\", event_col=\"E\")\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "cph.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Definir las variables predictoras\n",
    "X = df_model.drop(columns=[\"dias_230\", \"E\"])  \n",
    "\n",
    "# Estandarizar las variables antes de aplicar PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Aplicar PCA (mantendremos suficientes componentes para capturar 95% de la varianza)\n",
    "pca = PCA(n_components=0.95)  # Retiene el 95% de la varianza\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Convertir el PCA a DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f\"PCA_{i+1}\" for i in range(X_pca.shape[1])])\n",
    "\n",
    "# Agregar las columnas de tiempo y E\n",
    "df_pca[\"dias_230\"] = df_model[\"dias_230\"].values\n",
    "df_pca[\"E\"] = df_model[\"E\"].values\n",
    "\n",
    "# Ver la varianza explicada por cada componente\n",
    "print(\"Varianza explicada por cada componente:\", pca.explained_variance_ratio_)\n",
    "print(\"Varianza total explicada:\", pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Definir modelo base (Regresión logística para clasificación)\n",
    "modelo_base = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Aplicar RFE para seleccionar las mejores características\n",
    "rfe = RFE(estimator=modelo_base, n_features_to_select=5)  # Seleccionar 5 mejores variables\n",
    "X_rfe = rfe.fit_transform(X_scaled, df_model[\"E\"])  # RFE sobre datos estandarizados\n",
    "\n",
    "# Obtener las variables seleccionadas\n",
    "variables_seleccionadas = X.columns[rfe.support_]\n",
    "print(\"Variables seleccionadas por RFE:\", variables_seleccionadas)\n",
    "\n",
    "# Crear un nuevo DataFrame con las variables seleccionadas\n",
    "df_rfe = df_model[[\"dias_230\", \"E\"] + list(variables_seleccionadas)]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
